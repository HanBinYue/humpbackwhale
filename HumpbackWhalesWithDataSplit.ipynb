{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainAnalysisExcel.csv',\n",
       " '.DS_Store',\n",
       " 'test',\n",
       " 'data.zip',\n",
       " 'trainexcel.xlsx',\n",
       " 'trainAnalysisExcel.xlsx',\n",
       " 'trainexcel.csv',\n",
       " 'train',\n",
       " 'train.csv',\n",
       " '~$trainAnalysisExcel.xlsx',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = os.path.expanduser('~/Dev/humpbackwhale/data')\n",
    "pretrainedmodeldir = os.path.expanduser('~/Dev/humpbackwhale/pretrainedmodels')\n",
    "os.listdir(os.path.expanduser(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(datadir + '/train.csv')\n",
    "#train_df = train_df[:500]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareImages(data, m, dataset):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, 128, 128, 3))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:\n",
    "        #load images into images of size 100x100x3\n",
    "        img = image.load_img(datadir+\"/\"+dataset+\"/\"+fig, target_size=(128, 128, 3))\n",
    "        x = image.img_to_array(img)\n",
    "        #x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        x = x.astype('float32')/255\n",
    "        X_train[count] = x\n",
    "        if (count%500 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "        count += 1\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    # print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_new_whales(train_df):\n",
    "    new_whale_less = train_df.copy()\n",
    "    new_whale_less = new_whale_less[new_whale_less.Id != 'new_whale']\n",
    "    \n",
    "    print(train_df.head())\n",
    "    new_whales = train_df.copy()\n",
    "    new_whales = new_whales[new_whales.Id == 'new_whale']\n",
    "    \n",
    "    return new_whale_less, new_whales\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image         Id\n",
      "0  0000e88ab.jpg  w_f48451c\n",
      "1  0001f9222.jpg  w_c3d896a\n",
      "2  00029d126.jpg  w_20df2c5\n",
      "3  00050a15a.jpg  new_whale\n",
      "4  0005c1ef8.jpg  new_whale\n",
      "            Image         Id\n",
      "3   00050a15a.jpg  new_whale\n",
      "4   0005c1ef8.jpg  new_whale\n",
      "5   0006e997e.jpg  new_whale\n",
      "7   000f0f2bf.jpg  new_whale\n",
      "11  001d7450c.jpg  new_whale\n"
     ]
    }
   ],
   "source": [
    "train_df, new_whales = split_new_whales(train_df)\n",
    "train_df.head()\n",
    "new_whales.head()\n",
    "print(new_whales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  1 ,  0000e88ab.jpg\n",
      "Processing image:  501 ,  0823f9df3.jpg\n"
     ]
    }
   ],
   "source": [
    "X = prepareImages(train_df, train_df.shape[0], \"train\")\n",
    "#X /= 100\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, label_encoder = prepare_labels(train_df['Id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Architecture neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Simple(): \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (128, 128, 3)))\n",
    "\n",
    "    model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D((2, 2), name='max_pool'))\n",
    "    model.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D((3, 3), name='avg_pool'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation=\"relu\", name='rl'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(y.shape[1], activation='softmax', name='sm'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load(pretrainedmodeldir+\"/DogResnet50Data.npz\")\n",
    "train_Resnet50 = bottleneck_features['train']\n",
    "test_Resnet50 = bottleneck_features['test']\n",
    "\n",
    "def resnet_model(trainbottleneckfeatures):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (128, 128, 3)))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D(input_shape=trainbottleneckfeatures.shape[1:]))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y.shape[1], activation='softmax', name='sm'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "def mobilenet_model():\n",
    "    base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(128, 128, 3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "    xx=base_model.output\n",
    "    xx=GlobalAveragePooling2D()(xx)\n",
    "    xx=Dense(1024,activation='relu')(xx) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    xx=Dense(1024,activation='relu')(xx) #dense layer 2\n",
    "    xx=Dense(512,activation='relu')(xx) #dense layer 3\n",
    "    xx=Dropout(0.8)(xx)\n",
    "    preds=Dense(y.shape[1],activation='softmax')(xx) #final layer with softmax activation\n",
    "    \n",
    "    model=Model(inputs=base_model.input,outputs=preds)\n",
    "    #for i,layer in enumerate(model.layers):\n",
    "        #print(i,layer.name)\n",
    "    print(model.summary())\n",
    "    # or if we want to set the first 20 layers of the network to be non-trainable\n",
    "    for layer in model.layers[:18]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[18:]:\n",
    "        layer.trainable=True\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "def resnet50_model(): \n",
    "    base_model = ResNet50(weights='imagenet', \n",
    "                      include_top=False, \n",
    "                      input_shape=(128, 128, 3))\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    for fc in [1024,1024]:\n",
    "        # New FC layer, random init\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "    # New softmax layer\n",
    "    preds = Dense(y.shape[1], activation='softmax')(x) \n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=preds)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.densenet.densenet121 import DenseNet121\n",
    "\n",
    "def DenseNet121():\n",
    "    base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(100,100,3))\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', name='fc2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.9, name='dropout_fc2')(x)\n",
    "    preds = Dense(y.shape[1], activation='softmax')(x) \n",
    "    model = Model(inputs=base_model.input, outputs=preds)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_Resnet50.shape[1:])\n",
    "#print(X.shape)\n",
    "#print(\"Resnet Model: \")\n",
    "#model = resnet_model(train_Resnet50)\n",
    "#print(\"mobile Net Model: \")\n",
    "model = mobilenet_model()\n",
    "#model = resnet50_model()\n",
    "#model = CNN_Simple()\n",
    "#model = DenseNet121()\n",
    "\n",
    "resumetraining = False\n",
    "if resumetraining:\n",
    "    model = load_model('historySimpleCnn.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config of training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highresimages = False\n",
    "imageaugmentation = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagen.fit(X_train)\n",
    "#history_model = model.fit(X, y, epochs=10, batch_size=500, verbose=1)\n",
    "history_model = model.fit_generator(datagen.flow(X, y, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 100, epochs=5)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('historySimpleCnn.h5')  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['acc'])\n",
    "plt.plot(history_model.history['acc'])\n",
    "plt.title('Model accuracy CNN Simple with HighRes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(np.array(X_test), verbose=1)\n",
    "#predictions = model.predict(np.array(X_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df = copy.copy(train_df)\n",
    "#for i, pred in enumerate(predictions):\n",
    "#    pred_df.loc[i, 'Id'] = label_encoder.inverse_transform(pred.argsort()[-5:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Prediction Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_per_image(label, predictions):\n",
    "    \"\"\"Computes the precision score of one image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : string\n",
    "            The true label of the image\n",
    "    predictions : list\n",
    "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"   \n",
    "    score = 0.0\n",
    "    try:\n",
    "        if not len(np.where(predictions == label)[0])==0:\n",
    "            score =  1.0/(float(np.where(predictions == label)[0]) + 1)\n",
    "            return score\n",
    "        else:\n",
    "            return 0.\n",
    "            \n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def map_per_set(labels, predictions):\n",
    "    \"\"\"Computes the average over multiple images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : list\n",
    "             A list of the true labels. (Only one true label per images allowed!)\n",
    "    predictions : list of list\n",
    "             A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"\n",
    "    return np.mean([map_per_image(l, p) for l,p in zip(labels, predictions)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalaccuracy = 0.\n",
    "totalaccuracy = map_per_set(train_df['Id'],pred_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(totalaccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission.csv (not in use for Udacity Capstone project, but created anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = os.listdir(datadir+\"/test/\")\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepareImages(test_df, test_df.shape[0], \"test\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(np.array(X), verbose=1)\n",
    "predictions = model.predict(np.array(X), verbose=1)\n",
    "#prediction_probs = model.predict_proba(np.array(X), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "    test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humpbackwhale",
   "language": "python",
   "name": "humpbackwhale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
