{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'test',\n",
       " 'data.zip',\n",
       " 'trainexcel.csv',\n",
       " 'train',\n",
       " 'train.csv',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = os.path.expanduser('~/Dev/humpbackwhale/data')\n",
    "pretrainedmodeldir = os.path.expanduser('~/Dev/humpbackwhale/pretrainedmodels')\n",
    "os.listdir(os.path.expanduser(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(datadir + '/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareImages(data, m, dataset):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, 100, 100, 3))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:\n",
    "        #load images into images of size 100x100x3\n",
    "        img = image.load_img(datadir+\"/\"+dataset+\"/\"+fig, target_size=(100, 100, 3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        X_train[count] = x\n",
    "        if (count%500 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "        count += 1\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareImagesResnet50(img_path):\n",
    "    \n",
    "    # returns prediction vector for image located at img_path\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    # print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "('Processing image: ', 1, ', ', '0000e88ab.jpg')\n",
      "('Processing image: ', 501, ', ', '04c72257b.jpg')\n",
      "('Processing image: ', 1001, ', ', '09cacb84d.jpg')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-144805e1ef8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-01ebd409b2d3>\u001b[0m in \u001b[0;36mprepareImages\u001b[0;34m(data, m, dataset)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#load images into images of size 100x100x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcelschneider/anaconda3/envs/humpbackwhale/lib/python2.7/site-packages/keras_preprocessing/image/utils.pyc\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'color_mode must be \"grayscale\", \"rgb\", or \"rgba\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcelschneider/anaconda3/envs/humpbackwhale/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, data, dither, palette, colors)\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcelschneider/anaconda3/envs/humpbackwhale/lib/python2.7/site-packages/PIL/ImageFile.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image file is truncated (%d bytes not processed)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = prepareImages(train_df, train_df.shape[0], \"train\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, label_encoder = prepare_labels(train_df['Id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25361, 5005)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = Sequential()\\n\\nmodel.add(Conv2D(32, (7, 7), strides = (1, 1), name = \\'conv0\\', input_shape = (100, 100, 3)))\\n\\nmodel.add(BatchNormalization(axis = 3, name = \\'bn0\\'))\\nmodel.add(Activation(\\'relu\\'))\\n\\nmodel.add(MaxPooling2D((2, 2), name=\\'max_pool\\'))\\nmodel.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\\nmodel.add(Activation(\\'relu\\'))\\nmodel.add(AveragePooling2D((3, 3), name=\\'avg_pool\\'))\\n\\nmodel.add(Flatten())\\nmodel.add(Dense(500, activation=\"relu\", name=\\'rl\\'))\\nmodel.add(Dropout(0.8))\\nmodel.add(Dense(y.shape[1], activation=\\'softmax\\', name=\\'sm\\'))\\n\\nmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=\"adam\", metrics=[\\'accuracy\\'])\\nmodel.summary()'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (100, 100, 3)))\n",
    "\n",
    "model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), name='max_pool'))\n",
    "model.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D((3, 3), name='avg_pool'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\", name='rl'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(y.shape[1], activation='softmax', name='sm'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load(pretrainedmodeldir+\"/DogResnet50Data.npz\")\n",
    "train_Resnet50 = bottleneck_features['train']\n",
    "test_Resnet50 = bottleneck_features['test']\n",
    "\n",
    "def resnet_model(trainbottleneckfeatures):\n",
    "    model = Sequential()\n",
    "    model.add(GlobalAveragePooling2D(input_shape=trainbottleneckfeatures.shape[1:]))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y.shape[1], activation='softmax', name='sm'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.summary\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected global_average_pooling2d_2_input to have shape (1, 1, 2048) but got array with shape (100, 100, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-637f8fabcf42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Resnet50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcelschneider/anaconda3/envs/humpbackwhale/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcelschneider/anaconda3/envs/humpbackwhale/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcelschneider/anaconda3/envs/humpbackwhale/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected global_average_pooling2d_2_input to have shape (1, 1, 2048) but got array with shape (100, 100, 3)"
     ]
    }
   ],
   "source": [
    "model = resnet_model(train_Resnet50)\n",
    "history = model.fit(X, y, epochs=10, batch_size=100, verbose=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c751cb850>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960\n"
     ]
    }
   ],
   "source": [
    "test = os.listdir(datadir+\"/test\")\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "('Processing image: ', 1, ', ', 'd25be2116.jpg')\n",
      "('Processing image: ', 501, ', ', 'ecf335309.jpg')\n",
      "('Processing image: ', 1001, ', ', '549ddf793.jpg')\n",
      "('Processing image: ', 1501, ', ', '1459de372.jpg')\n",
      "('Processing image: ', 2001, ', ', '59e6e5011.jpg')\n",
      "('Processing image: ', 2501, ', ', 'f9293c32b.jpg')\n",
      "('Processing image: ', 3001, ', ', '7fdc46c0e.jpg')\n",
      "('Processing image: ', 3501, ', ', 'e0421d14a.jpg')\n",
      "('Processing image: ', 4001, ', ', 'bc03470dc.jpg')\n",
      "('Processing image: ', 4501, ', ', '48fa5169f.jpg')\n",
      "('Processing image: ', 5001, ', ', 'b09d98273.jpg')\n",
      "('Processing image: ', 5501, ', ', 'e6071c71f.jpg')\n",
      "('Processing image: ', 6001, ', ', '9aefd155f.jpg')\n",
      "('Processing image: ', 6501, ', ', 'cf91564b8.jpg')\n",
      "('Processing image: ', 7001, ', ', '82f45e027.jpg')\n",
      "('Processing image: ', 7501, ', ', '165c7bf64.jpg')\n"
     ]
    }
   ],
   "source": [
    "X = prepareImages(test_df, test_df.shape[0], \"test\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960/7960 [==============================] - 29s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(np.array(X), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "    test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humpbackwhale",
   "language": "python",
   "name": "humpbackwhale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
